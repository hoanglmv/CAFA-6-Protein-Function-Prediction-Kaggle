import os
import pickle
import pandas as pd
import numpy as np
from Bio import SeqIO
from ete3 import NCBITaxa
from tqdm import tqdm

# ==========================================
# Cáº¤U HÃŒNH
# ==========================================
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
TRAIN_TAX_PATH = os.path.join(BASE_DIR, "Train", "train_taxonomy.tsv")
TEST_FASTA_PATH = os.path.join(BASE_DIR, "Test", "testsuperset.fasta")
OUTPUT_PATH = os.path.join("models", "ver5", "taxonomy_group_mapping.pkl") # NÆ¡i lÆ°u file map

# Táº¡o thÆ° má»¥c output náº¿u chÆ°a cÃ³
os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)

# ==========================================
# CLASS Xá»¬ LÃ NHÃ“M (GROUPER)
# ==========================================
class TaxonGrouper:
    def __init__(self):
        print("â³ Khá»Ÿi táº¡o NCBI Database (Láº§n Ä‘áº§u cháº¡y sáº½ táº£i ~300MB)...")
        self.ncbi = NCBITaxa() # Tá»± Ä‘á»™ng táº£i/update database náº¿u cáº§n
        
        # Äá»‹nh nghÄ©a 4 nhÃ³m chÃ­nh (Superkingdoms) theo NCBI TaxID
        self.SUPERKINGDOMS = {
            2759: 0,   # Eukaryota (NhÃ¢n thá»±c: NgÆ°á»i, Náº¥m, CÃ¢y...)
            2: 1,      # Bacteria (Vi khuáº©n)
            2157: 2,   # Archaea (Cá»• khuáº©n)
            10239: 3   # Viruses (Virus)
        }
        self.num_classes = 4
        self.cache = {} # LÆ°u káº¿t quáº£ tra cá»©u Ä‘á»ƒ tÄƒng tá»‘c

    def get_one_hot(self, tax_id):
        # 1. Kiá»ƒm tra cache
        if tax_id in self.cache:
            return self.cache[tax_id]
        
        # Vector máº·c Ä‘á»‹nh [0,0,0,0] (Unknown)
        vector = np.zeros(self.num_classes, dtype=np.float32)
        
        try:
            tid = int(tax_id)
            # 2. Láº¥y dÃ²ng dÃµi tá»• tiÃªn (Lineage)
            # get_lineage tráº£ vá» list cÃ¡c ID tá»« gá»‘c Ä‘áº¿n ngá»n
            lineage = self.ncbi.get_lineage(tid)
            
            # 3. Kiá»ƒm tra xem tá»• tiÃªn cÃ³ náº±m trong 4 nhÃ³m chÃ­nh khÃ´ng
            for ancestor in lineage:
                if ancestor in self.SUPERKINGDOMS:
                    idx = self.SUPERKINGDOMS[ancestor]
                    vector[idx] = 1.0
                    break 
        except Exception:
            # Lá»—i thÆ°á»ng gáº·p: TaxID khÃ´ng cÃ³ trong DB cá»§a ete3 (má»›i quÃ¡ hoáº·c bá»‹ xÃ³a)
            # Giá»¯ nguyÃªn vector 0
            pass
            
        # 4. LÆ°u cache
        self.cache[tax_id] = vector
        return vector

# ==========================================
# MAIN PROCESS
# ==========================================
def main():
    grouper = TaxonGrouper()
    final_mapping = {} # Dictionary: {EntryID: OneHotVector}
    
    # --- BÆ¯á»šC 1: Xá»¬ LÃ Táº¬P TRAIN ---
    print(f"ğŸ“– Äang Ä‘á»c Train: {TRAIN_TAX_PATH}")
    # File tsv khÃ´ng header: Cá»™t 0 lÃ  EntryID, Cá»™t 1 lÃ  TaxID
    try:
        df_train = pd.read_csv(TRAIN_TAX_PATH, sep='\t', header=None, names=['EntryID', 'TaxID'], dtype=str)
        unique_train_tax = df_train['TaxID'].unique()
        print(f"   -> TÃ¬m tháº¥y {len(unique_train_tax)} loÃ i trong Train.")
        
        # Pre-calculate cho cÃ¡c loÃ i (Ä‘á»ƒ Ä‘á»¡ gá»i ete3 nhiá»u láº§n)
        print("   -> Äang nhÃ³m cÃ¡c loÃ i Train...")
        tax_to_vec_train = {}
        for tax in tqdm(unique_train_tax):
            tax_to_vec_train[tax] = grouper.get_one_hot(tax)
            
        # Map vÃ o tá»«ng EntryID
        print("   -> Mapping EntryID...")
        for _, row in tqdm(df_train.iterrows(), total=len(df_train)):
            final_mapping[row['EntryID']] = tax_to_vec_train[row['TaxID']]
            
    except Exception as e:
        print(f"âŒ Lá»—i Ä‘á»c Train: {e}")

    # --- BÆ¯á»šC 2: Xá»¬ LÃ Táº¬P TEST ---
    print(f"ğŸ“– Äang Ä‘á»c Test: {TEST_FASTA_PATH}")
    test_entries = []
    unique_test_tax = set()
    
    # Parse FASTA Ä‘á»ƒ láº¥y ID vÃ  TaxID
    for record in tqdm(SeqIO.parse(TEST_FASTA_PATH, "fasta")):
        # Header: "A0A0C5B5G6 9606" -> ID: A0A0C5B5G6, Tax: 9606
        parts = record.description.split()
        entry_id = parts[0]
        tax_id = parts[1] if len(parts) >= 2 and parts[1].isdigit() else "0"
        
        test_entries.append((entry_id, tax_id))
        unique_test_tax.add(tax_id)
        
    print(f"   -> TÃ¬m tháº¥y {len(unique_test_tax)} loÃ i trong Test.")
    
    # Pre-calculate cho Test
    print("   -> Äang nhÃ³m cÃ¡c loÃ i Test...")
    tax_to_vec_test = {}
    for tax in tqdm(unique_test_tax):
        tax_to_vec_test[tax] = grouper.get_one_hot(tax)
        
    # Map vÃ o EntryID
    print("   -> Mapping Test Entries...")
    for entry_id, tax_id in test_entries:
        final_mapping[entry_id] = tax_to_vec_test[tax_id]

    # --- BÆ¯á»šC 3: LÆ¯U Káº¾T QUáº¢ ---
    print(f"ğŸ’¾ Äang lÆ°u káº¿t quáº£ vÃ o {OUTPUT_PATH}...")
    with open(OUTPUT_PATH, 'wb') as f:
        pickle.dump(final_mapping, f)
        
    print("âœ… HOÃ€N Táº¤T!")
    print(f"- Tá»•ng sá»‘ Protein Ä‘Ã£ map: {len(final_mapping)}")
    
    # Test thá»­ 1 máº«u
    sample_id = list(final_mapping.keys())[0]
    print(f"- Máº«u ({sample_id}): {final_mapping[sample_id]}")

if __name__ == "__main__":
    main()