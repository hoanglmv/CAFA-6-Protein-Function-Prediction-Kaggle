{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. Data Viewing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from IPython.display import display\n",
        "\n",
        "data_dir = \"../data/Train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train_terms.tsv...\n",
            "train_terms.tsv head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EntryID</th>\n",
              "      <th>term</th>\n",
              "      <th>aspect</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q5W0B1</td>\n",
              "      <td>GO:0000785</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q5W0B1</td>\n",
              "      <td>GO:0004842</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q5W0B1</td>\n",
              "      <td>GO:0051865</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q5W0B1</td>\n",
              "      <td>GO:0006275</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q5W0B1</td>\n",
              "      <td>GO:0006513</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  EntryID        term aspect\n",
              "0  Q5W0B1  GO:0000785      C\n",
              "1  Q5W0B1  GO:0004842      F\n",
              "2  Q5W0B1  GO:0051865      P\n",
              "3  Q5W0B1  GO:0006275      P\n",
              "4  Q5W0B1  GO:0006513      P"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load train_terms.tsv\n",
        "print(\"Loading train_terms.tsv...\")\n",
        "train_terms_path = os.path.join(data_dir, \"train_terms.tsv\")\n",
        "train_terms_df = pd.read_csv(train_terms_path, sep=\"\\t\")\n",
        "print(\"train_terms.tsv head:\")\n",
        "display(train_terms_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_sequences.fasta head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence_id</th>\n",
              "      <th>accession</th>\n",
              "      <th>entry_name</th>\n",
              "      <th>db_source</th>\n",
              "      <th>description</th>\n",
              "      <th>OS</th>\n",
              "      <th>OX</th>\n",
              "      <th>GN</th>\n",
              "      <th>PE</th>\n",
              "      <th>SV</th>\n",
              "      <th>length</th>\n",
              "      <th>sequence</th>\n",
              "      <th>header</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0A0C5B5G6</td>\n",
              "      <td>A0A0C5B5G6</td>\n",
              "      <td>MOTSC_HUMAN</td>\n",
              "      <td>sp</td>\n",
              "      <td>Mitochondrial-derived peptide MOTS-c</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>MT-RNR1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>16</td>\n",
              "      <td>MRWQEMGYIFYPRKLR</td>\n",
              "      <td>sp|A0A0C5B5G6|MOTSC_HUMAN Mitochondrial-derive...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A0JNW5</td>\n",
              "      <td>A0JNW5</td>\n",
              "      <td>BLT3B_HUMAN</td>\n",
              "      <td>sp</td>\n",
              "      <td>Bridge-like lipid transfer protein family memb...</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>BLTP3B</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1464</td>\n",
              "      <td>MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...</td>\n",
              "      <td>sp|A0JNW5|BLT3B_HUMAN Bridge-like lipid transf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A0JP26</td>\n",
              "      <td>A0JP26</td>\n",
              "      <td>POTB3_HUMAN</td>\n",
              "      <td>sp</td>\n",
              "      <td>POTE ankyrin domain family member B3</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>POTEB3</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>581</td>\n",
              "      <td>MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...</td>\n",
              "      <td>sp|A0JP26|POTB3_HUMAN POTE ankyrin domain fami...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A0PK11</td>\n",
              "      <td>A0PK11</td>\n",
              "      <td>CLRN2_HUMAN</td>\n",
              "      <td>sp</td>\n",
              "      <td>Clarin-2</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>CLRN2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>232</td>\n",
              "      <td>MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...</td>\n",
              "      <td>sp|A0PK11|CLRN2_HUMAN Clarin-2 OS=Homo sapiens...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A1A4S6</td>\n",
              "      <td>A1A4S6</td>\n",
              "      <td>RHG10_HUMAN</td>\n",
              "      <td>sp</td>\n",
              "      <td>Rho GTPase-activating protein 10</td>\n",
              "      <td>Homo sapiens</td>\n",
              "      <td>9606</td>\n",
              "      <td>ARHGAP10</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>786</td>\n",
              "      <td>MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...</td>\n",
              "      <td>sp|A1A4S6|RHG10_HUMAN Rho GTPase-activating pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sequence_id   accession   entry_name db_source  \\\n",
              "0  A0A0C5B5G6  A0A0C5B5G6  MOTSC_HUMAN        sp   \n",
              "1      A0JNW5      A0JNW5  BLT3B_HUMAN        sp   \n",
              "2      A0JP26      A0JP26  POTB3_HUMAN        sp   \n",
              "3      A0PK11      A0PK11  CLRN2_HUMAN        sp   \n",
              "4      A1A4S6      A1A4S6  RHG10_HUMAN        sp   \n",
              "\n",
              "                                         description            OS    OX  \\\n",
              "0               Mitochondrial-derived peptide MOTS-c  Homo sapiens  9606   \n",
              "1  Bridge-like lipid transfer protein family memb...  Homo sapiens  9606   \n",
              "2               POTE ankyrin domain family member B3  Homo sapiens  9606   \n",
              "3                                           Clarin-2  Homo sapiens  9606   \n",
              "4                   Rho GTPase-activating protein 10  Homo sapiens  9606   \n",
              "\n",
              "         GN PE SV  length                                           sequence  \\\n",
              "0   MT-RNR1  1  1      16                                   MRWQEMGYIFYPRKLR   \n",
              "1    BLTP3B  1  2    1464  MAGIIKKQILKHLSRFTKNLSPDKINLSTLKGEGELKNLELDEEVL...   \n",
              "2    POTEB3  1  2     581  MVAEVCSMPAASAVKKPFDLRSKMGKWCHHRFPCCRGSGKSNMGTS...   \n",
              "3     CLRN2  1  1     232  MPGWFKKAWYGLASLLSFSSFILIIVALVVPHWLSGKILCQTGVDL...   \n",
              "4  ARHGAP10  1  1     786  MGLQPLEFSDCYLDSPWFRERIRAHEAELERTNKFIKELIKDGKNL...   \n",
              "\n",
              "                                              header  \n",
              "0  sp|A0A0C5B5G6|MOTSC_HUMAN Mitochondrial-derive...  \n",
              "1  sp|A0JNW5|BLT3B_HUMAN Bridge-like lipid transf...  \n",
              "2  sp|A0JP26|POTB3_HUMAN POTE ankyrin domain fami...  \n",
              "3  sp|A0PK11|CLRN2_HUMAN Clarin-2 OS=Homo sapiens...  \n",
              "4  sp|A1A4S6|RHG10_HUMAN Rho GTPase-activating pr...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total sequences loaded: 82404\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "train_sequences_path = os.path.join(data_dir, \"train_sequences.fasta\")\n",
        "\n",
        "sequences = []\n",
        "current_sequence_id = None\n",
        "current_sequence = []\n",
        "current_header = None\n",
        "\n",
        "def parse_header(header_line):\n",
        "    \"\"\"\n",
        "    Input: header_line: string without leading '>'\n",
        "    Return: dict with parsed fields:\n",
        "      - header: full header (raw)\n",
        "      - db_source, accession, entry_name, description, OS, OX, GN, PE, SV\n",
        "    \"\"\"\n",
        "    header = header_line.strip()\n",
        "    result = {'header': header,\n",
        "              'db_source': None, 'accession': None, 'entry_name': None,\n",
        "              'description': None, 'OS': None, 'OX': None, 'GN': None, 'PE': None, 'SV': None}\n",
        "\n",
        "    # primary token (something like sp|A0JNW5|BLT3B_HUMAN)\n",
        "    parts = header.split(' ', 1)\n",
        "    primary = parts[0]\n",
        "    rest = parts[1] if len(parts) > 1 else ''\n",
        "    primary_parts = primary.split('|')\n",
        "    if len(primary_parts) >= 3:\n",
        "        result['db_source'] = primary_parts[0]\n",
        "        result['accession'] = primary_parts[1]\n",
        "        result['entry_name'] = primary_parts[2]\n",
        "    else:\n",
        "        # fallback: set whole primary into entry_name\n",
        "        result['entry_name'] = primary\n",
        "\n",
        "    # description is the text before the first \" OS=\" token (if present)\n",
        "    if ' OS=' in rest:\n",
        "        desc, fields_str = rest.split(' OS=', 1)\n",
        "        result['description'] = desc.strip()\n",
        "        fields_str = 'OS=' + fields_str  # restore the OS= for parsing\n",
        "    else:\n",
        "        result['description'] = rest.strip()\n",
        "        fields_str = ''\n",
        "\n",
        "    # normalize delimiters then split into key=value tokens\n",
        "    if fields_str:\n",
        "        # ensure consistent separators for known keys\n",
        "        for key in [' OX=', ' GN=', ' PE=', ' SV=']:\n",
        "            fields_str = fields_str.replace(key, '|' + key.strip())\n",
        "        # Also prefix OS= if it wasn't prefixed by '|'\n",
        "        fields_str = fields_str.replace('OS=', 'OS=').lstrip('|')\n",
        "        for token in fields_str.split('|'):\n",
        "            if '=' not in token:\n",
        "                continue\n",
        "            k, v = token.split('=', 1)\n",
        "            k = k.strip()\n",
        "            v = v.strip()\n",
        "            if k in result:\n",
        "                result[k] = v\n",
        "            else:\n",
        "                # assign to known ones explicitly\n",
        "                if k == 'OS':\n",
        "                    result['OS'] = v\n",
        "                elif k == 'OX':\n",
        "                    result['OX'] = v\n",
        "                elif k == 'GN':\n",
        "                    result['GN'] = v\n",
        "                elif k == 'PE':\n",
        "                    result['PE'] = v\n",
        "                elif k == 'SV':\n",
        "                    result['SV'] = v\n",
        "    return result\n",
        "\n",
        "# read file safely\n",
        "try:\n",
        "    with open(train_sequences_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.rstrip('\\n')\n",
        "            if not line:\n",
        "                continue\n",
        "            if line.startswith('>'):\n",
        "                # save previous sequence\n",
        "                if current_sequence_id is not None:\n",
        "                    seq_str = ''.join(current_sequence)\n",
        "                    row = {\n",
        "                        'sequence_id': current_sequence_id,\n",
        "                        'sequence': seq_str,\n",
        "                        'length': len(seq_str),\n",
        "                    }\n",
        "                    # attach parsed header fields\n",
        "                    row.update(current_header)\n",
        "                    sequences.append(row)\n",
        "\n",
        "                # start new record\n",
        "                header_line = line[1:].strip()\n",
        "                current_header = parse_header(header_line)\n",
        "                current_sequence_id = current_header.get('accession') or current_header.get('entry_name') or header_line\n",
        "                current_sequence = []\n",
        "            else:\n",
        "                # sequence lines: remove whitespace and append\n",
        "                current_sequence.append(line.strip())\n",
        "\n",
        "        # final record\n",
        "        if current_sequence_id is not None:\n",
        "            seq_str = ''.join(current_sequence)\n",
        "            row = {\n",
        "                'sequence_id': current_sequence_id,\n",
        "                'sequence': seq_str,\n",
        "                'length': len(seq_str),\n",
        "            }\n",
        "            row.update(current_header)\n",
        "            sequences.append(row)\n",
        "\n",
        "except FileNotFoundError:\n",
        "    raise FileNotFoundError(f\"Không tìm thấy file: {train_sequences_path}. Kiểm tra lại data_dir hoặc tên file.\")\n",
        "\n",
        "# build dataframe and display\n",
        "train_sequences_df = pd.DataFrame(sequences)\n",
        "\n",
        "# reorder columns for nicer view (if present)\n",
        "preferred_cols = ['sequence_id', 'accession', 'entry_name', 'db_source', 'description',\n",
        "                  'OS', 'OX', 'GN', 'PE', 'SV', 'length', 'sequence', 'header'] \n",
        "cols = [c for c in preferred_cols if c in train_sequences_df.columns] + \\\n",
        "       [c for c in train_sequences_df.columns if c not in preferred_cols]\n",
        "\n",
        "train_sequences_df = train_sequences_df[cols]\n",
        "\n",
        "print(\"train_sequences.fasta head:\")\n",
        "display(train_sequences_df.head())\n",
        "print(\"\\nTotal sequences loaded:\", len(train_sequences_df))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading train_taxonomy.tsv...\n",
            "train_taxonomy.tsv head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A0A0C5B5G6</th>\n",
              "      <th>9606</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A0JNW5</td>\n",
              "      <td>9606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A0JP26</td>\n",
              "      <td>9606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A0PK11</td>\n",
              "      <td>9606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A1A4S6</td>\n",
              "      <td>9606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A1A519</td>\n",
              "      <td>9606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  A0A0C5B5G6  9606\n",
              "0     A0JNW5  9606\n",
              "1     A0JP26  9606\n",
              "2     A0PK11  9606\n",
              "3     A1A4S6  9606\n",
              "4     A1A519  9606"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load train_taxonomy.tsv\n",
        "print(\"Loading train_taxonomy.tsv...\")\n",
        "train_taxonomy_path = os.path.join(data_dir, \"train_taxonomy.tsv\")\n",
        "train_taxonomy_df = pd.read_csv(train_taxonomy_path, sep=\"\\t\")\n",
        "print(\"train_taxonomy.tsv head:\")\n",
        "display(train_taxonomy_df.head())\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading go-basic.obo...\n",
            "go-basic.obo head:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>namespace</th>\n",
              "      <th>def</th>\n",
              "      <th>is_a</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GO:0000001</td>\n",
              "      <td>mitochondrion inheritance</td>\n",
              "      <td>biological_process</td>\n",
              "      <td>The distribution of mitochondria, including th...</td>\n",
              "      <td>[GO:0048308, GO:0048311]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GO:0000002</td>\n",
              "      <td>mitochondrial genome maintenance</td>\n",
              "      <td>biological_process</td>\n",
              "      <td>The maintenance of the structure and integrity...</td>\n",
              "      <td>[GO:0007005]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GO:0000003</td>\n",
              "      <td>obsolete reproduction</td>\n",
              "      <td>biological_process</td>\n",
              "      <td>OBSOLETE. The production of new individuals th...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GO:0000005</td>\n",
              "      <td>obsolete ribosomal chaperone activity</td>\n",
              "      <td>molecular_function</td>\n",
              "      <td>OBSOLETE. Assists in the correct assembly of r...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GO:0000006</td>\n",
              "      <td>high-affinity zinc transmembrane transporter a...</td>\n",
              "      <td>molecular_function</td>\n",
              "      <td>Enables the transfer of zinc ions (Zn2+) from ...</td>\n",
              "      <td>[GO:0005385]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id                                               name  \\\n",
              "0  GO:0000001                          mitochondrion inheritance   \n",
              "1  GO:0000002                   mitochondrial genome maintenance   \n",
              "2  GO:0000003                              obsolete reproduction   \n",
              "3  GO:0000005              obsolete ribosomal chaperone activity   \n",
              "4  GO:0000006  high-affinity zinc transmembrane transporter a...   \n",
              "\n",
              "            namespace                                                def  \\\n",
              "0  biological_process  The distribution of mitochondria, including th...   \n",
              "1  biological_process  The maintenance of the structure and integrity...   \n",
              "2  biological_process  OBSOLETE. The production of new individuals th...   \n",
              "3  molecular_function  OBSOLETE. Assists in the correct assembly of r...   \n",
              "4  molecular_function  Enables the transfer of zinc ions (Zn2+) from ...   \n",
              "\n",
              "                       is_a  \n",
              "0  [GO:0048308, GO:0048311]  \n",
              "1              [GO:0007005]  \n",
              "2                       NaN  \n",
              "3                       NaN  \n",
              "4              [GO:0005385]  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Load go-basic.obo into a DataFrame\n",
        "print(\"Loading go-basic.obo...\")\n",
        "go_obo_path = os.path.join(data_dir, \"go-basic.obo\")\n",
        "terms = []\n",
        "current_term = {}\n",
        "\n",
        "with open(go_obo_path, 'r') as f:\n",
        "    for line in f:\n",
        "        line = line.strip()\n",
        "        if line == '[Term]':\n",
        "            if current_term:\n",
        "                terms.append(current_term)\n",
        "            current_term = {}\n",
        "        elif line.startswith('id:'):\n",
        "            current_term['id'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('name:'):\n",
        "            current_term['name'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('namespace:'):\n",
        "            current_term['namespace'] = line.split(':', 1)[1].strip()\n",
        "        elif line.startswith('def:'):\n",
        "            current_term['def'] = line.split(':', 1)[1].strip().strip('\"')\n",
        "        elif line.startswith('is_a:'):\n",
        "            # Extract only the GO ID, ignore the name after '!'\n",
        "            is_a_id = line.split(':', 1)[1].split('!', 1)[0].strip()\n",
        "            if 'is_a' not in current_term:\n",
        "                current_term['is_a'] = []\n",
        "            current_term['is_a'].append(is_a_id)\n",
        "    if current_term:  # Add the last term\n",
        "        terms.append(current_term)\n",
        "\n",
        "go_obo_df = pd.DataFrame(terms)\n",
        "print(\"go-basic.obo head:\")\n",
        "display(go_obo_df.head())\n",
        "print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loading complete.\n",
            "train_sequences_df columns: Index(['sequence_id', 'accession', 'entry_name', 'db_source', 'description',\n",
            "       'OS', 'OX', 'GN', 'PE', 'SV', 'length', 'sequence', 'header'],\n",
            "      dtype='object')\n",
            "train_taxonomy_df columns: Index(['A0A0C5B5G6', '9606'], dtype='object')\n",
            "go_obo_df columns: Index(['id', 'name', 'namespace', 'def', 'is_a'], dtype='object')\n",
            "train_terms_df columns: Index(['EntryID', 'term', 'aspect'], dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(\"Data loading complete.\")\n",
        "print(\"train_sequences_df columns:\", train_sequences_df.columns)\n",
        "print(\"train_taxonomy_df columns:\", train_taxonomy_df.columns)\n",
        "print(\"go_obo_df columns:\", go_obo_df.columns)\n",
        "print(\"train_terms_df columns:\", train_terms_df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, json, warnings, time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, average_precision_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "print(\"PyTorch version:\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TF-IDF limits to avoid huge dense tensors on GPU\n",
        "TFIDF_MAX_FEATURES = 50000   # lower if memory is tight\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 8\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "DROPOUT = 0.3\n",
        "HIDDEN_DIM = 1024\n",
        "RANDOM_STATE = 42\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- 0. Load precomputed resources (assume train_terms_df and train_sequences_df exist) ----------\n",
        "# If not present, load from files (adapt paths as needed)\n",
        "if 'train_terms_df' not in globals():\n",
        "    train_terms_df = pd.read_csv(os.path.join(TRAIN_DIR, 'train_terms.tsv'), sep='\\t')\n",
        "if 'train_sequences_df' not in globals():\n",
        "    # use your existing parse function or data already loaded in session\n",
        "    raise RuntimeError(\"train_sequences_df not found in globals. Load it first.\")\n",
        "\n",
        "# map sequences: sequence_id -> sequence\n",
        "seq_map = dict(zip(train_sequences_df['sequence_id'], train_sequences_df['sequence']))\n",
        "all_entry_ids = set(train_terms_df['EntryID'].unique()).intersection(seq_map.keys())\n",
        "entries = sorted(all_entry_ids)\n",
        "seqs = [seq_map[e] for e in entries]\n",
        "print(f\"Train proteins with sequences: {len(entries)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- 1. TF-IDF features ----------\n",
        "vectorizer = TfidfVectorizer(analyzer='char', ngram_range=(3,3), min_df=2, max_features=TFIDF_MAX_FEATURES)\n",
        "X_sparse = vectorizer.fit_transform(seqs)\n",
        "print(\"TF-IDF shape (sparse):\", X_sparse.shape)\n",
        "\n",
        "# ---------- 2. Build multi-label Y (we'll train per-aspect; here show MF/CC/BP loop as before) ----------\n",
        "aspect_names = {'F': 'MF', 'P': 'BP', 'C': 'CC'}\n",
        "models_summary = {}\n",
        "def eval_best_threshold(y_true, y_prob, thresholds=np.linspace(0.1,0.9,17)):\n",
        "    best_f1, best_t = 0.0, 0.5\n",
        "    for t in thresholds:\n",
        "        y_pred = (y_prob >= t).astype(int)\n",
        "        f1 = f1_score(y_true, y_pred, average='micro', zero_division=0)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_t = f1, t\n",
        "    return best_t, best_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ---------- 3. loop aspects and train PyTorch MLP ----------\n",
        "for aspect_code, aspect_label in aspect_names.items():\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(f\"Training aspect {aspect_label} ({aspect_code})\")\n",
        "    # gather labels for proteins in 'entries' order\n",
        "    labels_map = train_terms_df[train_terms_df['aspect']==aspect_code].groupby('EntryID')['term'].apply(list).to_dict()\n",
        "    y_labels = [labels_map.get(e, []) for e in entries]\n",
        "    mlb = MultiLabelBinarizer()\n",
        "    Y = mlb.fit_transform(y_labels)\n",
        "    n_labels = Y.shape[1]\n",
        "    print(\"Number of labels (terms):\", n_labels)\n",
        "    if n_labels == 0:\n",
        "        print(\"No labels for this aspect; skipping.\")\n",
        "        continue\n",
        "\n",
        "    # train/val split\n",
        "    X_train_idx, X_val_idx, Y_train, Y_val = train_test_split(\n",
        "        np.arange(len(entries)), Y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "    # convert sparse -> dense float32 (be careful with memory). If too big, reduce TFIDF_MAX_FEATURES.\n",
        "    X = X_sparse.tocsr()\n",
        "    X_train = X[X_train_idx].toarray().astype(np.float32)\n",
        "    X_val = X[X_val_idx].toarray().astype(np.float32)\n",
        "    print(\"Dense shapes:\", X_train.shape, X_val.shape)\n",
        "\n",
        "    # Build datasets and dataloaders\n",
        "    train_ds = TensorDataset(torch.from_numpy(X_train), torch.from_numpy(Y_train.astype(np.float32)))\n",
        "    val_ds = TensorDataset(torch.from_numpy(X_val), torch.from_numpy(Y_val.astype(np.float32)))\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Simple MLP\n",
        "    class MLP(nn.Module):\n",
        "        def __init__(self, input_dim, hidden_dim, out_dim, dropout=0.3):\n",
        "            super().__init__()\n",
        "            self.net = nn.Sequential(\n",
        "                nn.Linear(input_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim, hidden_dim//2),\n",
        "                nn.BatchNorm1d(hidden_dim//2),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(dropout),\n",
        "                nn.Linear(hidden_dim//2, out_dim)\n",
        "            )\n",
        "        def forward(self, x):\n",
        "            return self.net(x)\n",
        "\n",
        "    model = MLP(input_dim=X_train.shape[1], hidden_dim=HIDDEN_DIM, out_dim=n_labels, dropout=DROPOUT).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "    criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # training loop with tqdm\n",
        "    best_val_f1 = -1.0\n",
        "    best_state = None\n",
        "    for epoch in range(1, EPOCHS+1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} train\", leave=False)\n",
        "        for xb, yb in pbar:\n",
        "            xb = xb.to(device); yb = yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * xb.size(0)\n",
        "            pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "\n",
        "        # validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        all_probs = []\n",
        "        all_trues = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                xb = xb.to(device); yb = yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = criterion(logits, yb)\n",
        "                val_loss += loss.item() * xb.size(0)\n",
        "                probs = torch.sigmoid(logits).cpu().numpy()\n",
        "                all_probs.append(probs)\n",
        "                all_trues.append(yb.cpu().numpy())\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        all_probs = np.vstack(all_probs)\n",
        "        all_trues = np.vstack(all_trues)\n",
        "\n",
        "        # compute micro F1 at default threshold 0.5 and also best threshold\n",
        "        f1_05 = f1_score(all_trues, (all_probs>=0.5).astype(int), average='micro', zero_division=0)\n",
        "        best_t, best_f1 = eval_best_threshold(all_trues, all_probs, thresholds=np.linspace(0.1,0.9,17))\n",
        "\n",
        "        print(f\"Epoch {epoch:02d} | train_loss={epoch_loss:.4f} val_loss={val_loss:.4f} val_f1@0.5={f1_05:.4f} best_f1={best_f1:.4f} (t={best_t:.2f})\")\n",
        "\n",
        "        # save best\n",
        "        if best_f1 > best_val_f1:\n",
        "            best_val_f1 = best_f1\n",
        "            best_state = {\n",
        "                'model_state': model.state_dict(),\n",
        "                'mlb_classes': list(mlb.classes_),\n",
        "                'vectorizer_vocab_size': X_train.shape[1],\n",
        "                'best_threshold': float(best_t),\n",
        "                'val_f1': float(best_f1)\n",
        "            }\n",
        "\n",
        "    # after epochs: restore best state and save model\n",
        "    if best_state is not None:\n",
        "        model.load_state_dict(best_state['model_state'])\n",
        "        # Save model checkpoint (PyTorch)\n",
        "        save_dir = os.path.join(BASE_DIR, 'models')\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "        fname = f\"mlp_aspect_{aspect_label}.pth\"\n",
        "        torch.save({\n",
        "            'model_state': model.state_dict(),\n",
        "            'mlb_classes': best_state['mlb_classes'],\n",
        "            'vectorizer': vectorizer,   # caution: may be large; you can save separately via pickle\n",
        "            'best_threshold': best_state['best_threshold'],\n",
        "            'val_f1': best_state['val_f1']\n",
        "        }, os.path.join(save_dir, fname))\n",
        "        print(f\"Saved best model for {aspect_label} to {os.path.join(save_dir, fname)} (val_f1={best_state['val_f1']:.4f})\")\n",
        "\n",
        "    models_summary[aspect_code] = {\n",
        "        'n_labels': n_labels,\n",
        "        'best_val_f1': float(best_val_f1),\n",
        "        'best_threshold': float(best_state['best_threshold']) if best_state is not None else None,\n",
        "        'model_path': os.path.join(save_dir, fname) if best_state is not None else None\n",
        "    }\n",
        "\n",
        "print(\"\\nTraining summary:\")\n",
        "print(json.dumps(models_summary, indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
