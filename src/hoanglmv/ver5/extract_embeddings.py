import os
import torch
import numpy as np
import pandas as pd
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModel
from Bio import SeqIO
import pickle
import sys

# ==========================================
# C·∫§U H√åNH
# ==========================================
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..','..'))
DATA_DIR = os.path.join(BASE_DIR, 'data')
MODEL_DIR = os.path.join(BASE_DIR, 'models', 'esm2_ver1')

# Input Files
TRAIN_PKL = os.path.join(BASE_DIR, 'models', 'ver5', 'processed_data.pkl') 
TEST_FASTA = os.path.join(DATA_DIR, 'Test', 'testsuperset.fasta')

# Output Files
TRAIN_EMB_PATH = os.path.join(MODEL_DIR, 'train_embeddings.npy')
TEST_EMB_PATH = os.path.join(MODEL_DIR, 'test_embeddings.npy')
TEST_IDS_PATH = os.path.join(MODEL_DIR, 'test_ids.pkl') 

# Model Config
# RTX 3060 12GB d∆∞ s·ª©c ch·∫°y b·∫£n 650M (t33). H√£y d√πng b·∫£n n√†y ƒë·ªÉ c√≥ k·∫øt qu·∫£ t·ªët h∆°n b·∫£n 8M (t6).
# MODEL_NAME = "facebook/esm2_t6_8M_UR50D" # Qu√° y·∫øu
MODEL_NAME = "facebook/esm2_t33_650M_UR50D" # Khuy√™n d√πng (Vector 1280 chi·ªÅu)

BATCH_SIZE = 32 # N·∫øu b·ªã tr√†n VRAM (OOM), h√£y gi·∫£m xu·ªëng 16
MAX_LEN = 512

os.makedirs(MODEL_DIR, exist_ok=True)

# --- C·∫§U H√åNH GPU CH·∫∂T CH·∫º ---
if torch.cuda.is_available():
    DEVICE = "cuda"
    gpu_name = torch.cuda.get_device_name(0)
    print(f"‚úÖ ƒê√É K√çCH HO·∫†T GPU: {gpu_name}")
    # B·∫≠t ch·∫ø ƒë·ªô t·ªëi ∆∞u to√°n h·ªçc cho GPU (Optional)
    torch.backends.cudnn.benchmark = True
else:
    print("‚ùå L·ªñI NGHI√äM TR·ªåNG: Kh√¥ng t√¨m th·∫•y GPU NVIDIA!")
    print("   Code s·∫Ω ch·∫°y tr√™n CPU v√† m·∫•t h√†ng gi·ªù ƒë·ªìng h·ªì.")
    print("   üëâ H√£y ki·ªÉm tra l·∫°i c√†i ƒë·∫∑t PyTorch v·ªõi l·ªánh: pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118")
    # D·ª´ng ch∆∞∆°ng tr√¨nh ngay l·∫≠p t·ª©c ƒë·ªÉ b·∫°n kh√¥ng t·ªën th·ªùi gian ch·∫°y CPU
    sys.exit("D·ª´ng ch∆∞∆°ng tr√¨nh do kh√¥ng c√≥ GPU.")

print(f"‚öôÔ∏è Model: {MODEL_NAME}")

# ==========================================
# H√ÄM TR√çCH XU·∫§T
# ==========================================
def extract_embeddings(sequence_list, model_name, save_path):
    print(f"üöÄ Loading Model...")
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModel.from_pretrained(model_name).to(DEVICE)
    model.eval()
    
    # S·ª≠ d·ª•ng Mixed Precision (FP16) ƒë·ªÉ ch·∫°y nhanh h∆°n v√† ti·∫øt ki·ªám VRAM tr√™n RTX 3060
    # scaler = torch.amp.GradScaler() # Ch·ªâ d√πng khi training, inference d√πng autocast l√† ƒë·ªß
    
    embeddings = []
    
    print(f"üîÑ ƒêang x·ª≠ l√Ω {len(sequence_list)} chu·ªói...")
    for i in tqdm(range(0, len(sequence_list), BATCH_SIZE)):
        batch_seqs = sequence_list[i : i + BATCH_SIZE]
        
        # Tokenize
        inputs = tokenizer(
            batch_seqs, 
            padding=True, 
            truncation=True, 
            max_length=MAX_LEN, 
            return_tensors="pt"
        ).to(DEVICE)
        
        with torch.no_grad():
            # Ch·∫°y ch·∫ø ƒë·ªô Mixed Precision (t·ª± ƒë·ªông d√πng FP16)
            with torch.cuda.amp.autocast():
                outputs = model(**inputs)
                last_hidden = outputs.last_hidden_state
                
                # Mean Pooling (c√≥ t√≠nh ƒë·∫øn Attention Mask)
                mask = inputs['attention_mask'].unsqueeze(-1).expand(last_hidden.size()).float()
                sum_embeddings = torch.sum(last_hidden * mask, dim=1)
                sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9)
                mean_embeddings = sum_embeddings / sum_mask
                
            # Chuy·ªÉn v·ªÅ CPU numpy ƒë·ªÉ ti·∫øt ki·ªám VRAM GPU
            embeddings.append(mean_embeddings.float().cpu().numpy())
            
    # G·ªôp v√† L∆∞u
    full_embeddings = np.vstack(embeddings)
    print(f"üíæ ƒêang l∆∞u file npy: {save_path} | Shape: {full_embeddings.shape}")
    np.save(save_path, full_embeddings)
    return full_embeddings

# ==========================================
# MAIN EXECUTION
# ==========================================
if __name__ == "__main__":
    # --- 1. EXTRACT TRAIN ---
    if os.path.exists(TRAIN_EMB_PATH):
        print(f"‚úÖ File {TRAIN_EMB_PATH} ƒë√£ t·ªìn t·∫°i. B·ªè qua.")
    else:
        print("üìñ ƒê·ªçc d·ªØ li·ªáu Train...")
        if not os.path.exists(TRAIN_PKL):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {TRAIN_PKL}")
            sys.exit()
            
        df_train = pd.read_pickle(TRAIN_PKL)
        sequences = df_train['sequence'].tolist()
        # V·ªá sinh chu·ªói protein
        sequences = [s.replace('U','X').replace('Z','X').replace('O','X').replace('B','X') for s in sequences]
        
        extract_embeddings(sequences, MODEL_NAME, TRAIN_EMB_PATH)

    # --- 2. EXTRACT TEST ---
    if os.path.exists(TEST_EMB_PATH):
        print(f"‚úÖ File {TEST_EMB_PATH} ƒë√£ t·ªìn t·∫°i. B·ªè qua.")
    else:
        print("üìñ ƒê·ªçc d·ªØ li·ªáu Test...")
        if not os.path.exists(TEST_FASTA):
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y file {TEST_FASTA}")
            sys.exit()

        test_ids = []
        test_seqs = []
        for record in SeqIO.parse(TEST_FASTA, "fasta"):
            test_ids.append(record.id)
            seq = str(record.seq).replace('U','X').replace('Z','X').replace('O','X').replace('B','X')
            test_seqs.append(seq)
            
        # L∆∞u ID ƒë·ªÉ d√πng cho file submission
        with open(TEST_IDS_PATH, 'wb') as f:
            pickle.dump(test_ids, f)
            
        extract_embeddings(test_seqs, MODEL_NAME, TEST_EMB_PATH)
        
    print("\nüéâ HO√ÄN T·∫§T TR√çCH XU·∫§T!")