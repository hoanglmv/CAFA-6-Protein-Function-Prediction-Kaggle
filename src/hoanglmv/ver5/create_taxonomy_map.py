import os
import pandas as pd
import numpy as np
from tqdm import tqdm
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer

# ==========================================
# C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N
# ==========================================
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..','..')) 
DATA_DIR = os.path.join(BASE_DIR, 'data')

# 1. File ch·ª©a ID lo√†i ƒë√£ h·ªçc (Train)
TRAIN_TAX_PATH = os.path.join(DATA_DIR, "Train", "train_taxonomy.tsv")

# 2. File ch·ª©a T√™n lo√†i (C·ªßa c·∫£ Train v√† Test)
# File n√†y Kaggle cung c·∫•p: TaxID <tab> Scientific Name
TAXON_LIST_PATH = os.path.join(DATA_DIR, "Test", "testsuperset-taxon-list.tsv")

OUTPUT_FILE = os.path.join(BASE_DIR, "models", "ver5", "taxonomy_mapping.tsv")

def main():
    print("üöÄ B·∫Øt ƒë·∫ßu Mapping Taxonomy...")

    # --- 1. Load Known IDs ---
    print(f"üìñ ƒê·ªçc Train IDs: {TRAIN_TAX_PATH}")
    # Train tax file: EntryID <tab> TaxID
    df_train = pd.read_csv(TRAIN_TAX_PATH, sep='\t', header=None, dtype=str)
    # L·∫•y danh s√°ch c√°c TaxID duy nh·∫•t c√≥ trong t·∫≠p Train
    known_tax_ids = set(df_train.iloc[:, 1].unique())
    print(f"‚úÖ Train set c√≥ {len(known_tax_ids)} lo√†i.")

    # --- 2. Load Names ---
    print(f"üìñ ƒê·ªçc danh s√°ch t√™n lo√†i: {TAXON_LIST_PATH}")
    # File n√†y c√≥ th·ªÉ c√≥ header ho·∫∑c kh√¥ng, check k·ªπ
    try:
        df_taxons = pd.read_csv(TAXON_LIST_PATH, sep='\t', encoding='latin-1', dtype=str)
        # Chu·∫©n h√≥a t√™n c·ªôt
        if 'Taxon_ID' not in df_taxons.columns and len(df_taxons.columns) >= 2:
             df_taxons = pd.read_csv(TAXON_LIST_PATH, sep='\t', header=None, names=['TaxID', 'SpeciesName'], encoding='latin-1', dtype=str)
        else:
             # Rename c·ªôt ƒë·∫ßu th√†nh TaxID, c·ªôt 2 th√†nh SpeciesName
             df_taxons.rename(columns={df_taxons.columns[0]: 'TaxID', df_taxons.columns[1]: 'SpeciesName'}, inplace=True)
    except Exception as e:
        print(f"‚ùå L·ªói ƒë·ªçc file Taxon List: {e}")
        return

    # --- 3. Ph√¢n lo·∫°i Known vs Unknown ---
    # Known: Nh·ªØng lo√†i c√≥ trong Train (ƒê√≠ch ƒë·∫øn)
    df_known = df_taxons[df_taxons['TaxID'].isin(known_tax_ids)].copy()
    
    # Unknown: Nh·ªØng lo√†i ch·ªâ c√≥ trong Test (C·∫ßn map)
    df_unknown = df_taxons[~df_taxons['TaxID'].isin(known_tax_ids)].copy()
    
    print(f"üìä Th·ªëng k√™:\n - Known Species: {len(df_known)}\n - Unknown Species: {len(df_unknown)}")

    final_mapping = []

    # --- 4. Direct Match (Map ch√≠nh n√≥) ---
    print("üîπ [1/2] Mapping Direct...")
    for _, row in df_known.iterrows():
        final_mapping.append({
            'Original_ID': row['TaxID'],
            'Mapped_ID': row['TaxID'],
            'Score': 1.0,
            'Method': 'Direct'
        })

    # --- 5. Semantic Match (T√¨m lo√†i g·∫ßn nh·∫•t) ---
    if len(df_unknown) > 0:
        print("üîπ [2/2] Mapping Semantic (Embedding)...")
        # Load model si√™u nh·∫π chuy√™n tr·ªã so s√°nh c√¢u
        model = SentenceTransformer('all-MiniLM-L6-v2') 
        
        known_names = df_known['SpeciesName'].tolist()
        known_ids = df_known['TaxID'].tolist()
        
        unknown_names = df_unknown['SpeciesName'].tolist()
        unknown_ids = df_unknown['TaxID'].tolist()
        
        print("   -> Embedding Known Names...")
        emb_known = model.encode(known_names, show_progress_bar=True)
        
        print("   -> Embedding Unknown Names...")
        emb_unknown = model.encode(unknown_names, show_progress_bar=True)
        
        print("   -> Calculating Similarity...")
        sim_matrix = cosine_similarity(emb_unknown, emb_known)
        
        for i in tqdm(range(len(unknown_ids))):
            best_idx = np.argmax(sim_matrix[i])
            best_score = sim_matrix[i][best_idx]
            
            final_mapping.append({
                'Original_ID': unknown_ids[i],
                'Mapped_ID': known_ids[best_idx], # ID lo√†i Known gi·ªëng nh·∫•t
                'Score': best_score,
                'Method': 'Semantic'
            })

    # --- 6. Save ---
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    pd.DataFrame(final_mapping).to_csv(OUTPUT_FILE, sep='\t', index=False)
    print(f"‚úÖ Xong! File map l∆∞u t·∫°i: {OUTPUT_FILE}")

if __name__ == "__main__":
    main()