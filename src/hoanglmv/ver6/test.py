import os
import pickle
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import models
from tqdm import tqdm

# ==========================================
# 1. Cáº¤U HÃŒNH
# ==========================================
class Config:
    # Sá»­a láº¡i sá»‘ lÆ°á»£ng dáº¥u .. tÃ¹y vÃ o vá»‹ trÃ­ báº¡n Ä‘áº·t file script
    # Giáº£ sá»­ file nÃ y náº±m á»Ÿ: src/hoanglmv/ver6/test.py -> lÃ¹i 3 cáº¥p vá» Project Root
    BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..'))
    
    # Input Data
    DATA_DIR = os.path.join(BASE_DIR, 'data', 'processed2')
    TEST_FILE = os.path.join(DATA_DIR, 'test.parquet')
    
    # Model Directory (NÆ¡i chá»©a model ver6 Ä‘Ã£ train)
    MODEL_DIR = os.path.join(BASE_DIR, 'models', 'ver6')
    
    # Output Submission (Sá»­a: LÆ°u trá»±c tiáº¿p vÃ o folder model)
    SUBMISSION_FILE = os.path.join(MODEL_DIR, 'submission.tsv')
    
    # Inference Params
    BATCH_SIZE = 256  # Batch lá»›n Ä‘á»ƒ cháº¡y nhanh hÆ¡n (vÃ¬ chá»‰ cáº§n feed forward)
    TOP_K = 60        # Chá»‰ láº¥y 60 nhÃ£n cÃ³ Ä‘iá»ƒm cao nháº¥t
    MIN_SCORE = 0.001 # Chá»‰ láº¥y nhÃ£n cÃ³ xÃ¡c suáº¥t > 0.1%

    @staticmethod
    def setup_gpu():
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            try:
                for gpu in gpus: tf.config.experimental.set_memory_growth(gpu, True)
                print(f"âœ… GPU Activated for Inference: {gpus[0].name}")
            except: pass
        else:
            print("âš ï¸ Running on CPU")

Config.setup_gpu()

# ==========================================
# 2. CUSTOM LOSS (Báº¯t buá»™c khai bÃ¡o Ä‘á»ƒ Load Model)
# ==========================================
class AsymmetricLoss(tf.keras.losses.Loss):
    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, **kwargs):
        super().__init__(**kwargs)
        self.gamma_neg, self.gamma_pos, self.clip, self.eps = gamma_neg, gamma_pos, clip, eps

    def call(self, y_true, y_pred):
        return 0.0 # KhÃ´ng dÃ¹ng khi test
    
    def get_config(self):
        return {'gamma_neg': self.gamma_neg, 'gamma_pos': self.gamma_pos, 'clip': self.clip, 'eps': self.eps}

# ==========================================
# 3. QUY TRÃŒNH Dá»° ÄOÃN (INFERENCE)
# ==========================================
def run_inference():
    print(f"ðŸš€ Báº¯t Ä‘áº§u Inference vá»›i model táº¡i: {Config.MODEL_DIR}")
    
    # --- BÆ¯á»šC 1: LOAD TÃ€I NGUYÃŠN ---
    print("   -> Loading Model & Label Map...")
    
    # 1.1 Load Model
    model_path = os.path.join(Config.MODEL_DIR, 'best_model.keras')
    if not os.path.exists(model_path):
        # Fallback náº¿u khÃ´ng cÃ³ best_model thÃ¬ tÃ¬m final_model
        model_path = os.path.join(Config.MODEL_DIR, 'final_model.keras')
        
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ KhÃ´ng tÃ¬m tháº¥y model táº¡i {Config.MODEL_DIR}")
        
    model = models.load_model(model_path, custom_objects={'AsymmetricLoss': AsymmetricLoss})
    
    # 1.2 Load Label Map (Index -> GO Term)
    map_path = os.path.join(Config.MODEL_DIR, 'idx_to_term.pkl')
    with open(map_path, 'rb') as f:
        idx_to_term = pickle.load(f)
    print(f"   -> Loaded mapping for {len(idx_to_term)} GO terms.")

    # --- BÆ¯á»šC 2: LOAD Dá»® LIá»†U TEST (PARQUET) ---
    print(f"   -> Reading Test File: {Config.TEST_FILE}")
    # Äá»c file parquet báº±ng pandas (nhanh vÃ  tá»‘i Æ°u)
    df = pd.read_parquet(Config.TEST_FILE)
    
    ids = df['id'].values
    # Chuyá»ƒn Ä‘á»•i list trong dataframe thÃ nh numpy matrix 2D
    # LÆ°u Ã½: Cáº§n np.stack Ä‘á»ƒ biáº¿n máº£ng cÃ¡c object array thÃ nh máº£ng 2D chuáº©n float32
    X_emb = np.stack(df['embedding'].values).astype(np.float32)
    X_tax = np.stack(df['superkingdom'].values).astype(np.float32)
    
    total_samples = len(ids)
    print(f"   -> Found {total_samples} samples.")
    
    # --- BÆ¯á»šC 3: Dá»° ÄOÃN & GHI FILE ---
    print(f"   -> Predicting & Writing to {Config.SUBMISSION_FILE}...")
    
    # Äáº£m báº£o thÆ° má»¥c tá»“n táº¡i (thÆ°á»ng model_dir Ä‘Ã£ cÃ³ rá»“i, nhÆ°ng check cho cháº¯c)
    os.makedirs(os.path.dirname(Config.SUBMISSION_FILE), exist_ok=True)

    with open(Config.SUBMISSION_FILE, 'w') as f:
        # Ghi Header (theo chuáº©n CAFA)
        f.write("ObjectId\tGO-Term\tPrediction\n")
        
        # Xá»­ lÃ½ theo batch Ä‘á»ƒ tiáº¿t kiá»‡m RAM
        # tqdm giÃºp hiá»‡n thanh tiáº¿n trÃ¬nh
        for i in tqdm(range(0, total_samples, Config.BATCH_SIZE), desc="Processing Batches"):
            end = min(i + Config.BATCH_SIZE, total_samples)
            
            # Láº¥y batch hiá»‡n táº¡i
            batch_emb = X_emb[i:end]
            batch_tax = X_tax[i:end]
            batch_ids = ids[i:end]
            
            # Predict (Äáº§u vÃ o lÃ  Dictionary khá»›p vá»›i tÃªn Layer trong train.py)
            preds = model.predict(
                {'input_embedding': batch_emb, 'input_taxonomy': batch_tax}, 
                verbose=0
            )
            
            # Xá»­ lÃ½ káº¿t quáº£ batch
            for j, pid in enumerate(batch_ids):
                probs = preds[j]
                
                # Chiáº¿n thuáº­t lá»c: Chá»‰ láº¥y Top K Ä‘iá»ƒm cao nháº¥t
                # np.argsort tráº£ vá» index cá»§a pháº§n tá»­ Ä‘Æ°á»£c sort tÄƒng dáº§n -> láº¥y [-TOP_K:] -> Ä‘áº£o ngÆ°á»£c [::-1]
                top_indices = np.argsort(probs)[-Config.TOP_K:][::-1]
                
                for idx in top_indices:
                    score = float(probs[idx])
                    
                    # Chá»‰ ghi náº¿u Ä‘iá»ƒm > ngÆ°á»¡ng tá»‘i thiá»ƒu
                    if score > Config.MIN_SCORE:
                        term = idx_to_term.get(idx, None)
                        if term:
                            f.write(f"{pid}\t{term}\t{score:.3f}\n")
                        
    print(f"\nâœ… HOÃ€N Táº¤T! File submission Ä‘Ã£ lÆ°u táº¡i: {Config.SUBMISSION_FILE}")

if __name__ == "__main__":
    run_inference()